{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9ps3FeUunC0"
   },
   "source": [
    "# Deep Learning: Introduction with Venn Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kzxi-xhGyH2i"
   },
   "source": [
    "\"Deep learning\" has been a challenge to define for many years, partly because it has been evolving. Perhaps a few Venn diagrams would help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94fb44hUygRp"
   },
   "source": [
    "1. The original Venn diagram from Drew Conway:\n",
    "\n",
    "<img src=\"https://images.squarespace-cdn.com/content/v1/5150aec6e4b0e340ec52710a/1364352051365-HZAS3CLBF7ABLE3F5OBY/ke17ZwdGBToddI8pDm48kB2M2-8_3EzuSSXvzQBRsa1Zw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxPe_8B-x4gq2tfVez1FwLYYZXud0o-3jV-FAs7tmkMHY-a7GzQZKbHRGZboWC-fOc/Data_Science_VD.png?format=1500w\">\n",
    "\n",
    "2. However, it turns out it was incomplete, the improved version 2.0 is this:\n",
    "\n",
    "<img src=\"https://3.bp.blogspot.com/-bvQxcwfqATQ/V-E_uTBc4VI/AAAAAAAAMGQ/Qa1Ntef-rs0E-mWx5pkVu-CPlREdvD0TwCLcB/s1600/VennDiagram2.png\" width=800>\n",
    "\n",
    "3. The standard Venn diagram defining \"deep learning\" is this:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/962/0*MLoBkTeTBu6Of2Xj\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id17BD7m1evw"
   },
   "source": [
    "A few alternative definitions:\n",
    "\n",
    "\n",
    "1.   **Deep learning has to do with complex neural networks.** [Patterson&Gibson] Here \"complex\" refers to neural networks which a) are not from the 80's, b) have a lot of neurons c) have a lot of connections d) are run on powerful computers e) are able to automatically extract features in the data.\n",
    "2.   **Deep learning is a class of machine learning algorithms that uses multiple layers to progressively extract higher-level features from the raw input.** [Wikipedia] \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4lxakJZ4aNu"
   },
   "source": [
    "<img src=\"https://qph.fs.quoracdn.net/main-qimg-3a839e177d70b43dd83dc77c486dad36\">\n",
    "\n",
    "One last Venn diagram which may help in your job search:\n",
    "\n",
    "<img src=\"https://3.bp.blogspot.com/-L_utsSrIS38/V-Fv5V4e98I/AAAAAAAAMHc/Jx6H2Zfk148bBt3p5-wzrwwi-lsXoijdQCLcB/s400/aiQeT.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb2rVaKb6MHi"
   },
   "source": [
    "# Artificial Neural Networks: Basic Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPeN0iBg_sem"
   },
   "source": [
    "## Artificial neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqsMCSBvT-8J"
   },
   "source": [
    "<img src=\"https://miro.medium.com/max/3000/1*WRG_Re8vGVuHDYigtq2IBA.jpeg\" width=700>\n",
    "\n",
    "For a given artificial neuron, let there be $m$ inputs with signals $x_1$ through $x_m$ arriving along $m$ connections with weights $\\omega_0$ through $\\omega_m$. The neuron computes the sum\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^m \\omega_i x_i + b = \\vec{\\omega}\\cdot \\vec{x} + b\n",
    "$$\n",
    "\n",
    "where $b$ is the bias. The activation function $\\varphi$ then maps this sum to a single output $y$:\n",
    "\n",
    "$$\n",
    "y = \\varphi(\\vec{\\omega}\\cdot \\vec{x} + b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFuA4CYuWDXj"
   },
   "source": [
    "## The basic structure of a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVfjvzkPWNkE"
   },
   "source": [
    "<img src=\"https://www.researchgate.net/publication/329216193/figure/fig3/AS:697582816870406@1543328112943/Architecture-of-multilayer-artificial-neural-network-with-error-backpropagation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfftsfOs65rQ"
   },
   "source": [
    "# A First Look at a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7WVfhsBqimN"
   },
   "source": [
    "## The MNIST dataset of handwritten digits (28x28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtTL_nds9T7G"
   },
   "source": [
    "Let's build a neural network which uses the Python library Keras to learn to classify the handwritten digits from the MNIST dataset: 28x28 pixels of grayscale images into 10 categories (0 through 9). The MNIST dataset has 60,000 training images and 10,000 test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AlgzRE0n6waI",
    "outputId": "63d34f8d-2a22-4dd4-cdbf-b6193b3b1af0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hRa0CwFqO6JB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fThYUrVq-YAx"
   },
   "source": [
    "The MNIST dataset comes preloaded in Keras as a set of four Numpy arrays: train_images and train_labels form the training set, while test_images and test_labels form the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ItVYM2dp8CMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ha6mIXO-qm0"
   },
   "source": [
    "Look at the training data first: note that the grayscale is an integer between 0 and 255. We will have to rescale it later to be between 0 and 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f-YHpyVBopP",
    "outputId": "f5ff8b63-c9ef-4d5f-9b41-4c950a626595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  51, 159, 253, 159,  50,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  48, 238, 252, 252, 252, 237,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         54, 227, 253, 252, 239, 233, 252,  57,   6,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  10,  60,\n",
       "        224, 252, 253, 252, 202,  84, 252, 253, 122,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 163, 252,\n",
       "        252, 252, 253, 252, 252,  96, 189, 253, 167,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  51, 238, 253,\n",
       "        253, 190, 114, 253, 228,  47,  79, 255, 168,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 238, 252, 252,\n",
       "        179,  12,  75, 121,  21,   0,   0, 253, 243,  50,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  38, 165, 253, 233, 208,\n",
       "         84,   0,   0,   0,   0,   0,   0, 253, 252, 165,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   7, 178, 252, 240,  71,  19,\n",
       "         28,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  57, 252, 252,  63,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 195,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 198, 253, 190,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 255, 253, 196,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  76, 246, 252, 112,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0, 253, 252, 148,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 230,  25,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   7, 135, 253, 186,  12,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 223,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   7, 131, 252, 225,  71,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 145,   0,   0,   0,   0,\n",
       "          0,   0,   0,  48, 165, 252, 173,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  86, 253, 225,   0,   0,   0,   0,\n",
       "          0,   0, 114, 238, 253, 162,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 249, 146,  48,  29,  85,\n",
       "        178, 225, 253, 223, 167,  56,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  85, 252, 252, 252, 229, 215, 252,\n",
       "        252, 252, 196, 130,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  28, 199, 252, 252, 253, 252, 252,\n",
       "        233, 145,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  25, 128, 252, 253, 252, 141,\n",
       "         37,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxi1kVAS8n0m",
    "outputId": "2e26b9ff-1721-4dc4-f976-30cc24d5cc4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMSjKcO38qJ8",
    "outputId": "dac0de59-675a-4646-93a6-980dad26219a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oo9pc15p_Wy5",
    "outputId": "ee1c6739-92f9-4be6-b246-66a9b059bcdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZe0994eO2Xv"
   },
   "source": [
    "Look at a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "ib8IQ5enO89L",
    "outputId": "69e27119-efd8-4abc-8a26-148a9aabdc3f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show one training sample\n",
    "image = train_images[-1]\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uti_KS-E_cwH"
   },
   "source": [
    "Then look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNYxWhO68vr8",
    "outputId": "4e0bd7ef-c25f-4198-ca72-d1cadd4dc908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiDk_Fmi80wg",
    "outputId": "32b3d9e0-35fd-4f7e-84d5-b4284199ccac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJYJHe80878g",
    "outputId": "08ca668a-2548-4943-958b-c867bd9f2f29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "4h38z7pgrfus",
    "outputId": "9d6bfc96-e024-491b-dd64-4a3b004c9978"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show one training sample\n",
    "image = test_images[-3]\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue4JQfQzroMJ"
   },
   "source": [
    "## Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2WUbbHx_4Yh"
   },
   "source": [
    "\n",
    "Let's build a very simple network with no hidden layers, i.e., with only two layers (fully connected). Since we are classifying 10 possible digits, the output layer is a 10-way softmax layer which will return an array of 10 probability scores (summing to 1). Each score is the probability that the current digit image belongs to the corresponding digit class.  \n",
    "\n",
    "Now, what about the remaining input layer? Recall that the image contains 28x28=784 pixels, so one possibility is to feed each pixel to its own neuron in the input layer.\n",
    "[Quiz: How many parameters does the input layer have in this case? Answer: 784+784=1568.]\n",
    "\n",
    "<img src=\"https://ml4a.github.io/images/figures/mnist_1layer.png\">\n",
    "\n",
    "However, there is also another possibility (which may seem like an overkill): feed **each** pixel to **each** neuron in the input layer:\n",
    "\n",
    "<img src=\"https://ml4a.github.io/images/figures/mnist_2layers.png\">\n",
    "\n",
    "How many parameters does the input layer have in this case? Let's say we choose 512 neurons in the input layer. The number of weights is 784x512=401,408 and the number of biases in the input layer is 512; therefore the total number of parameters is 401,408+512=401,920!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sH4_nMal_jBE",
    "outputId": "62fbdc6f-fe09-4884-c089-346fdd3ed885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19Uw7Ch8IHaJ"
   },
   "source": [
    "Note that the input layer requires an extra parameter \"input_shape\" to specify the format of the input data. This is needed in order to define the size of the weight matrix for the input layer.\n",
    "\n",
    "For the subsequent layers, we don't have to specify this information because the program already knows how many neurons are in each layer. For example, the second layer has 512x10=5120 weights and 10 biases for a total of 5130 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_IWtRhtJRlL"
   },
   "source": [
    "In order to make the network ready for training, we have to specify three more things: \n",
    "\n",
    "1. A **loss function**, i.e., how to calculate the penalty for getting the answers wrong in the training data. \n",
    "2. An **optimizer**, i.e., the mechanism for updating the weights.\n",
    "3. The **metrics** used to evaluate the performance. Here we only care about the accuracy of the classification.\n",
    "\n",
    "We will see and discuss some other options later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "xJXC6HKbByVQ"
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlQxwmWhKPJS"
   },
   "source": [
    "Before training, we need to preprocess the data:\n",
    "\n",
    "1. Reshaping it into the shape that the network expects.\n",
    "2. Scaling it so that the values are between 0 and 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CbFz2TUUB_Ar"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIv8lGevLJYX"
   },
   "source": [
    "We also need to categorically encode the labels, since this is what the loss function \"categorical_crossentropy\" expects:\n",
    "\n",
    "$$\n",
    "L = - \\sum_{i=1}^C y_i \\log \\hat y_i\n",
    "$$\n",
    "\n",
    "Here $C=10$ is the number of categories, $y_i$ is the truth label for the $i$-th category (either zero or one) and $\\hat y_i$ is the NN output for the $i$-th category. In our case here, the activation function for the output layer was the softmax function\n",
    "\n",
    "$$\n",
    "\\hat y_i = \\sigma(\\vec{s})_i = \\frac{e^{s_i}}{\\sum_{j=1}^C e^{s_j}}\n",
    "$$\n",
    "where $s_i$ is the sum computed by the $i$-th neuron in the output layer. \n",
    "\n",
    "There is only one element of the target vector $\\vec{y}$ which is non-zero, and furthermore, that element is equal to 1. This element marks the true class \"c\", so that the loss function in this case can be simplified as\n",
    "\n",
    "$$\n",
    "L = - \\log \\left( \\frac{e^{s_c}}{\\sum_{j=1}^C e^{s_j}} \\right)\n",
    "$$\n",
    "\n",
    "Basically \"to_categorical\" is one-hot encoding the original categorical label from an integer in [0,9] to a 10-dimensional unit vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "oSfGy7L8CC7H"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RZraU17VH6u"
   },
   "source": [
    "Next we train the network. In Keras this is done with a call to the \"fit\" method - we **fit** the model to its training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-sYBvYnCGTb",
    "outputId": "44a59d16-20cd-4ba7-b797-b9d74c286990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2572 - accuracy: 0.9259\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1049 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0697 - accuracy: 0.9788\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0499 - accuracy: 0.9847\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0373 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f0d330a58>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwqFcXlNVwxB"
   },
   "source": [
    "Two quantities are displayed during the training: the loss and the accuracy over the training data. In this case 5 epochs are sufficient to reach a decent accuracy of 98.9\\%.\n",
    "\n",
    "Now let us check the performance of the trained model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQ_bBSYfCKZ-",
    "outputId": "b6ee6958-54cc-4024-da02-18e85d2ed992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9780\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1M1o2s8HCZXy",
    "outputId": "f1676c62-284e-4422-f075-fe05cf01cdff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XarGv5-nWd4C"
   },
   "source": [
    "The test accuracy is 97.8\\% which is less than the 98.9\\% achieved during training. This gap is an indication of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C24eqUwEZyU0"
   },
   "source": [
    "## What did the network actually learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri7bC69aclcY"
   },
   "source": [
    "This is the result from the simpler version of our network (with one pixel per neuron in the input layer). The lowest weight is black, the highest weight is white. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7Z7i1Acs-E5"
   },
   "source": [
    "<img src=\"https://ml4a.github.io/images/figures/rolled_weights_mnist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCrVBpU6dT2B"
   },
   "source": [
    "Even though the network did not know the shape of the digits, it found decent approximations for them. It is as if the digits from each class have been averaged.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "171BVxBFtc7z"
   },
   "source": [
    "# Variations in the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDN9nN-6zGFa"
   },
   "source": [
    "For a complete list of available network components refer to the <a href=\"https://keras.io/api/\">Keras documentation</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al6Aah1JtfyF"
   },
   "source": [
    "## Activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64ACNBvfyj3v"
   },
   "source": [
    "See the complete list of <a href=\"https://keras.io/api/layers/activations/\">layer activation functions</a> in Keras.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Vivienne_Sze/publication/315667264/figure/fig3/AS:669951052496900@1536740186369/Various-forms-of-non-linear-activation-functions-Figure-adopted-from-Caffe-Tutorial.png\" width=700>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WGIgo8Y4ct4"
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1p3MZaG_4yte"
   },
   "source": [
    "See the list of available <a href=\"https://keras.io/api/losses/\">loss functions</a> in Keras. \n",
    "\n",
    "For **regression**, some commonly used loss functions are\n",
    "\n",
    "1. <a href=\"https://keras.io/api/losses/regression_losses/#meansquarederror-class\">Mean squared error</a>\n",
    "2. <a href=\"https://keras.io/api/losses/regression_losses/#meanabsoluteerror-class\">Mean absolute error</a>\n",
    "3. <a href=\"https://keras.io/api/losses/regression_losses/#meanabsolutepercentageerror-class\">Mean absolute percentage error</a>\n",
    "4. <a href=\"https://keras.io/api/losses/regression_losses/#meansquaredlogarithmicerror-class\">Mean squared logarithmic error</a>\n",
    "\n",
    "\n",
    "For **categorization**, some commonly used loss functions are\n",
    "\n",
    "1. <a href=\"https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class\">Binary cross-entropy</a> (for 2 classes)\n",
    "2. <a href=\"https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class\">Categorical cross-entropy</a>\n",
    "3. <a href=\"https://keras.io/api/losses/hinge_losses/#hinge-class\">Hinge loss</a>. With the conventions $y=\\pm1$ it is given by\n",
    "$$\n",
    "L = \\max \\left(0, 1-y\\hat y\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIQFhD5n14DZ"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F94tT19i2bdj"
   },
   "source": [
    "See the list of available <a href=\"https://keras.io/api/optimizers/\">optimizers</a> in Keras. The basic one is stochastic gradient descent (SGD).\n",
    "\n",
    "For further information refer to <a href=\"https://ruder.io/optimizing-gradient-descent/index.html\">the blog</a>,\n",
    "<a href=\"https://www.slideshare.net/SebastianRuder/optimization-for-deep-learning\">the slides</a> or \n",
    "<a href=\"https://arxiv.org/abs/1609.04747\">the review paper</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fliM3NHk8Iuw"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7gnQVQQ_7RM"
   },
   "source": [
    "A metric is a function that is used to judge the performance of the model.\n",
    "Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss function as a metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWnXrXq-8BWQ"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzDVFfJKBD2x"
   },
   "source": [
    "In addition to model parameters, we also have additional parameters which can be tuned to make the networks train faster and better. Hyperparameter selection focuses on ensuring that the model neither overfits nor underfits the training data, while learning the structure of the data as quickly as possible.\n",
    "\n",
    "1. **Layer number and size.** Self-explanatory.\n",
    "2. **Learning rate.** It affects the rate at which the network parameters are adjusted during optimization. It is a coefficient that scales the size of the steps (updates) that the network takes on its way to the minimum. If the error is large and the gradient is steep, the step is large and there is a danger to overshoot the minimum. On the other hand, if the step is too small, we will crawl too slowly towards the minimum, and training will take a long time. The learning rate can be constant or adjusted dynamically.\n",
    "3. **Regularization.** Regularization helps with the effects of out-of-control parameters by limiting parameter size. Operationally this is done by adding to the loss function a cost associated with the size of the weights: either L1 (absolute values) or L2 (squares). \n",
    "4. **Momentum.** A picture is worth a thousand words:\n",
    "<a href=\"https://distill.pub/2017/momentum/\">Why momentum really works</a>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj0-bBN1AoHW"
   },
   "source": [
    "## Built-in small datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4EBLUJjAxuF"
   },
   "source": [
    "The **tf.keras.datasets** module provides a few toy <a href=\"https://keras.io/api/datasets/\">datasets</a> (already-vectorized, in Numpy format) that can be used for debugging a model or creating simple code examples. We will explore those next time in team exercises."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "T9ps3FeUunC0",
    "fb2rVaKb6MHi",
    "fPeN0iBg_sem",
    "OFuA4CYuWDXj",
    "s7WVfhsBqimN",
    "Ue4JQfQzroMJ",
    "C24eqUwEZyU0"
   ],
   "name": "DL_NeuralNetworks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
